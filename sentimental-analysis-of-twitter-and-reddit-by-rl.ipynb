{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5875cb2c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-26T12:24:28.417114Z",
     "iopub.status.busy": "2025-10-26T12:24:28.416891Z",
     "iopub.status.idle": "2025-10-26T12:24:41.790578Z",
     "shell.execute_reply": "2025-10-26T12:24:41.789653Z"
    },
    "papermill": {
     "duration": 13.379972,
     "end_time": "2025-10-26T12:24:41.791741",
     "exception": false,
     "start_time": "2025-10-26T12:24:28.411769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset distribution:\n",
      "category\n",
      " 1    15830\n",
      " 0    13042\n",
      "-1     8277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "category\n",
      " 1    0.426122\n",
      " 0    0.351073\n",
      "-1    0.222805\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 1: Balanced Undersampling\n",
      "============================================================\n",
      "Minority class size: 8277\n",
      "Balanced dataset size: 24831\n",
      "Balanced distribution:\n",
      "category\n",
      "-1    8277\n",
      " 1    8277\n",
      " 0    8277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 2: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "Training set distribution:\n",
      "category\n",
      " 1    0.426127\n",
      " 0    0.351061\n",
      "-1    0.222812\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set distribution:\n",
      "category\n",
      " 1    0.426110\n",
      " 0    0.351099\n",
      "-1    0.222790\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 3: Hybrid Sampling (Target size between min and max)\n",
      "============================================================\n",
      "Target size per class: 12383\n",
      "Hybrid dataset size: 33043\n",
      "Hybrid distribution:\n",
      "category\n",
      " 1    12383\n",
      " 0    12383\n",
      "-1     8277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "############################################################\n",
      "COMPARING ALL SAMPLING STRATEGIES\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Training with: Balanced Undersampling\n",
      "============================================================\n",
      "Vocabulary size: 17313\n",
      "Valid signatures: 190\n",
      "\n",
      "ACCURACY: 0.6689 (66.89%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.68      0.61      0.64      2483\n",
      "     Neutral       0.71      0.70      0.71      2483\n",
      "    Positive       0.62      0.70      0.66      2484\n",
      "\n",
      "    accuracy                           0.67      7450\n",
      "   macro avg       0.67      0.67      0.67      7450\n",
      "weighted avg       0.67      0.67      0.67      7450\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      1514       351       618\n",
      "True Neu       310      1739       434\n",
      "True Pos       408       346      1730\n",
      "\n",
      "============================================================\n",
      "Training with: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "Vocabulary size: 21744\n",
      "Valid signatures: 117\n",
      "\n",
      "ACCURACY: 0.6283 (62.83%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.57      0.19      0.28      2483\n",
      "     Neutral       0.72      0.61      0.66      3913\n",
      "    Positive       0.59      0.87      0.70      4749\n",
      "\n",
      "    accuracy                           0.63     11145\n",
      "   macro avg       0.63      0.56      0.55     11145\n",
      "weighted avg       0.63      0.63      0.60     11145\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       466       577      1440\n",
      "True Neu        94      2406      1413\n",
      "True Pos       263       356      4130\n",
      "\n",
      "============================================================\n",
      "Training with: Hybrid Sampling\n",
      "============================================================\n",
      "Vocabulary size: 20136\n",
      "Valid signatures: 139\n",
      "\n",
      "ACCURACY: 0.6719 (67.19%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.40      0.50      2483\n",
      "     Neutral       0.72      0.71      0.72      3715\n",
      "    Positive       0.64      0.81      0.71      3715\n",
      "\n",
      "    accuracy                           0.67      9913\n",
      "   macro avg       0.67      0.64      0.64      9913\n",
      "weighted avg       0.67      0.67      0.66      9913\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      1004       631       848\n",
      "True Neu       203      2651       861\n",
      "True Pos       326       383      3006\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.6689 (66.89%)\n",
      "Stratified (Original)              : 0.6283 (62.83%)\n",
      "Hybrid Sampling                    : 0.6719 (67.19%)\n",
      "\n",
      "🏆 BEST STRATEGY: Hybrid Sampling\n",
      "   Accuracy: 0.6719 (67.19%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === 1️⃣ Load data ===\n",
    "df = pd.read_csv(\"/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Reddit_Data.csv\")\n",
    "df = df[['clean_comment', 'category']].dropna()\n",
    "\n",
    "print(\"Original dataset distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 1: BALANCED UNDERSAMPLING ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1: Balanced Undersampling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the minority class size\n",
    "min_class_size = df['category'].value_counts().min()\n",
    "print(f\"Minority class size: {min_class_size}\")\n",
    "\n",
    "# Sample equal amounts from each class\n",
    "df_balanced = pd.concat([\n",
    "    df[df['category'] == -1].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 0].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 1].sample(min_class_size, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "print(f\"Balanced dataset size: {len(df_balanced)}\")\n",
    "print(\"Balanced distribution:\")\n",
    "print(df_balanced['category'].value_counts())\n",
    "\n",
    "# Split balanced data\n",
    "train_df_balanced, test_df_balanced = train_test_split(\n",
    "    df_balanced, test_size=0.3, random_state=42, stratify=df_balanced['category']\n",
    ")\n",
    "\n",
    "# === STRATEGY 2: STRATIFIED SPLIT (keeps original distribution) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2: Stratified Split (Original Distribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_df_stratified, test_df_stratified = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(\"Training set distribution:\")\n",
    "print(train_df_stratified['category'].value_counts(normalize=True))\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df_stratified['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 3: WEIGHTED BALANCED (Oversample minority, undersample majority) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3: Hybrid Sampling (Target size between min and max)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = df['category'].value_counts()\n",
    "target_size = int(np.mean(class_counts))  # Use average as target\n",
    "print(f\"Target size per class: {target_size}\")\n",
    "\n",
    "df_hybrid = pd.concat([\n",
    "    df[df['category'] == -1].sample(\n",
    "        min(target_size, class_counts[-1]), \n",
    "        replace=(target_size > class_counts[-1]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 0].sample(\n",
    "        min(target_size, class_counts[0]), \n",
    "        replace=(target_size > class_counts[0]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 1].sample(\n",
    "        min(target_size, class_counts[1]), \n",
    "        replace=(target_size > class_counts[1]), \n",
    "        random_state=42\n",
    "    )\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Hybrid dataset size: {len(df_hybrid)}\")\n",
    "print(\"Hybrid distribution:\")\n",
    "print(df_hybrid['category'].value_counts())\n",
    "\n",
    "train_df_hybrid, test_df_hybrid = train_test_split(\n",
    "    df_hybrid, test_size=0.3, random_state=42, stratify=df_hybrid['category']\n",
    ")\n",
    "\n",
    "# === Function to train and evaluate ===\n",
    "def train_and_evaluate(train_df, test_df, strategy_name):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training with: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    train_df[\"tokens\"] = train_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    test_df[\"tokens\"] = test_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:  # Minimum 2 occurrences\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    test_df[\"tags\"] = test_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Drop rare signatures\n",
    "    min_occ = 3  # Lower threshold for balanced data\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(word_tag_dict)}\")\n",
    "    print(f\"Valid signatures: {len(valid_sigs)}\")\n",
    "    \n",
    "    # Predict\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in test_df[\"tags\"]]\n",
    "    test_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(test_df[\"pred\"] == test_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\nACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_df[\"category\"], test_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(test_df[\"category\"], test_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# === Run all strategies ===\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"COMPARING ALL SAMPLING STRATEGIES\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results['Balanced Undersampling'] = train_and_evaluate(\n",
    "    train_df_balanced.copy(), test_df_balanced.copy(), \n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results['Stratified (Original)'] = train_and_evaluate(\n",
    "    train_df_stratified.copy(), test_df_stratified.copy(), \n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results['Hybrid Sampling'] = train_and_evaluate(\n",
    "    train_df_hybrid.copy(), test_df_hybrid.copy(), \n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === Final comparison ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for strategy, acc in results.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "best_strategy = max(results, key=results.get)\n",
    "print(f\"\\n🏆 BEST STRATEGY: {best_strategy}\")\n",
    "print(f\"   Accuracy: {results[best_strategy]:.4f} ({results[best_strategy]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c700dcf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:24:41.800141Z",
     "iopub.status.busy": "2025-10-26T12:24:41.799932Z",
     "iopub.status.idle": "2025-10-26T12:25:25.541270Z",
     "shell.execute_reply": "2025-10-26T12:25:25.540067Z"
    },
    "papermill": {
     "duration": 43.747047,
     "end_time": "2025-10-26T12:25:25.542659",
     "exception": false,
     "start_time": "2025-10-26T12:24:41.795612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORIGINAL DATASET\n",
      "============================================================\n",
      "Total samples: 162969\n",
      "\n",
      "Class distribution:\n",
      "category\n",
      " 1.0    72249\n",
      " 0.0    55211\n",
      "-1.0    35509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "category\n",
      " 1.0    0.443330\n",
      " 0.0    0.338782\n",
      "-1.0    0.217888\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 1: Balanced Undersampling\n",
      "============================================================\n",
      "Original class counts:\n",
      "  Class -1: 35509 samples\n",
      "  Class 0: 55211 samples\n",
      "  Class 1: 72249 samples\n",
      "\n",
      "Minority class size: 35509\n",
      "\n",
      "✂️ Sampled 35509 from each class\n",
      "📦 Total balanced dataset: 106527 samples (65.4% of original)\n",
      "🗑️ Removed: 56442 samples (34.6%)\n",
      "\n",
      "Balanced distribution:\n",
      "category\n",
      " 0.0    35509\n",
      "-1.0    35509\n",
      " 1.0    35509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 106,527 samples (balanced)\n",
      "🧪 Testing: 16,933 samples (from original distribution)\n",
      "   Test set is 10.4% of original data\n",
      "\n",
      "Test set distribution (original imbalance):\n",
      "category\n",
      " 1.0    0.438729\n",
      " 0.0    0.338511\n",
      "-1.0    0.222760\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 2: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "📦 Total dataset: 162969 samples (100% of original)\n",
      "   Training: 114078 samples (70%)\n",
      "   Testing: 48891 samples (30%)\n",
      "\n",
      "Training set distribution:\n",
      "category\n",
      " 1.0    50574\n",
      " 0.0    38648\n",
      "-1.0    24856\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "category\n",
      " 1.0    21675\n",
      " 0.0    16563\n",
      "-1.0    10653\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 3: Hybrid Sampling (Target size between min and max)\n",
      "============================================================\n",
      "Original class sizes:\n",
      "  Class -1: 35509 samples\n",
      "  Class 0: 55211 samples\n",
      "  Class 1: 72249 samples\n",
      "\n",
      "Target size per class: 54323 (average of all classes)\n",
      "\n",
      "Sampling details:\n",
      "  Class -1: 35,509 → 54,323 ⬆️ OVERSAMPLING\n",
      "  Class 0: 55,211 → 54,323 ⬇️ UNDERSAMPLING\n",
      "  Class 1: 72,249 → 54,323 ⬇️ UNDERSAMPLING\n",
      "\n",
      "📦 Total hybrid dataset: 144155 samples (88.5% of original)\n",
      "Hybrid distribution:\n",
      "category\n",
      " 0.0    54323\n",
      " 1.0    54323\n",
      "-1.0    35509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 144,155 samples (hybrid balanced)\n",
      "🧪 Testing: 18,816 samples\n",
      "   Test set is 11.5% of original data\n",
      "\n",
      "############################################################\n",
      "COMPARING ALL SAMPLING STRATEGIES\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Training with: Balanced Undersampling\n",
      "============================================================\n",
      "Vocabulary size: 31185\n",
      "Valid signatures: 346\n",
      "\n",
      "ACCURACY: 0.8340 (83.40%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.84      0.78      3772\n",
      "     Neutral       0.84      0.87      0.86      5732\n",
      "    Positive       0.90      0.80      0.85      7429\n",
      "\n",
      "    accuracy                           0.83     16933\n",
      "   macro avg       0.82      0.84      0.83     16933\n",
      "weighted avg       0.84      0.83      0.84     16933\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      3184       192       396\n",
      "True Neu       457      4990       285\n",
      "True Pos       738       743      5948\n",
      "\n",
      "============================================================\n",
      "Training with: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "Vocabulary size: 32197\n",
      "Valid signatures: 257\n",
      "\n",
      "ACCURACY: 0.7785 (77.85%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.58      0.66     10653\n",
      "     Neutral       0.80      0.78      0.79     16563\n",
      "    Positive       0.77      0.88      0.82     21675\n",
      "\n",
      "    accuracy                           0.78     48891\n",
      "   macro avg       0.78      0.75      0.76     48891\n",
      "weighted avg       0.78      0.78      0.77     48891\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      6231      1903      2519\n",
      "True Neu       548     12860      3155\n",
      "True Pos      1489      1214     18972\n",
      "\n",
      "============================================================\n",
      "Training with: Hybrid Sampling\n",
      "============================================================\n",
      "Vocabulary size: 38658\n",
      "Valid signatures: 346\n",
      "\n",
      "ACCURACY: 0.8741 (87.41%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.72      0.76      3962\n",
      "     Neutral       0.87      0.95      0.91      6392\n",
      "    Positive       0.90      0.89      0.90      8462\n",
      "\n",
      "    accuracy                           0.87     18816\n",
      "   macro avg       0.86      0.85      0.86     18816\n",
      "weighted avg       0.87      0.87      0.87     18816\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      2839       506       617\n",
      "True Neu       137      6056       199\n",
      "True Pos       496       413      7553\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Data Usage Summary:\n",
      "------------------------------------------------------------\n",
      "Original dataset: 162,969 samples\n",
      "  Strategy 1 (Balanced):  106,527 samples (65.4%)\n",
      "  Strategy 2 (Stratified): 162,969 samples (100.0%)\n",
      "  Strategy 3 (Hybrid):     144,155 samples (88.5%)\n",
      "\n",
      "Accuracy Results:\n",
      "------------------------------------------------------------\n",
      "Balanced Undersampling             : 0.8340 (83.40%)\n",
      "Stratified (Original)              : 0.7785 (77.85%)\n",
      "Hybrid Sampling                    : 0.8741 (87.41%)\n",
      "\n",
      "🏆 BEST STRATEGY: Hybrid Sampling\n",
      "   Accuracy: 0.8741 (87.41%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === 1️⃣ Load data ===\n",
    "df = pd.read_csv(\"/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Twitter_Data.csv\")\n",
    "df = df[['clean_text', 'category']].dropna()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ORIGINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 1: BALANCED UNDERSAMPLING ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1: Balanced Undersampling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the minority class size\n",
    "class_counts = df['category'].value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "print(f\"Original class counts:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    print(f\"  Class {cat}: {class_counts.get(cat, 0)} samples\")\n",
    "print(f\"\\nMinority class size: {min_class_size}\")\n",
    "\n",
    "# Sample equal amounts from each class\n",
    "df_balanced = pd.concat([\n",
    "    df[df['category'] == -1].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 0].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 1].sample(min_class_size, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "print(f\"\\n✂️ Sampled {min_class_size} from each class\")\n",
    "print(f\"📦 Total balanced dataset: {len(df_balanced)} samples ({len(df_balanced)/len(df)*100:.1f}% of original)\")\n",
    "print(f\"🗑️ Removed: {len(df) - len(df_balanced)} samples ({(len(df)-len(df_balanced))/len(df)*100:.1f}%)\")\n",
    "print(\"\\nBalanced distribution:\")\n",
    "print(df_balanced['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL balanced data for training, test on ORIGINAL distribution\n",
    "# This is more realistic - train balanced, test on real-world imbalanced data\n",
    "train_df_balanced = df_balanced.copy()\n",
    "\n",
    "# Create a separate test set from ORIGINAL data (not used in training)\n",
    "remaining_indices = df.index.difference(df_balanced.index)\n",
    "test_df_balanced = df.loc[remaining_indices].sample(\n",
    "    frac=0.3, random_state=42\n",
    ")  # 30% of remaining data\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_balanced):,} samples (balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_balanced):,} samples (from original distribution)\")\n",
    "print(f\"   Test set is {len(test_df_balanced)/len(df)*100:.1f}% of original data\")\n",
    "print(\"\\nTest set distribution (original imbalance):\")\n",
    "print(test_df_balanced['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 2: STRATIFIED SPLIT (keeps original distribution) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2: Stratified Split (Original Distribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_df_stratified, test_df_stratified = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(f\"📦 Total dataset: {len(df)} samples (100% of original)\")\n",
    "print(f\"   Training: {len(train_df_stratified)} samples (70%)\")\n",
    "print(f\"   Testing: {len(test_df_stratified)} samples (30%)\")\n",
    "print(\"\\nTraining set distribution:\")\n",
    "print(train_df_stratified['category'].value_counts())\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df_stratified['category'].value_counts())\n",
    "\n",
    "# === STRATEGY 3: WEIGHTED BALANCED (Oversample minority, undersample majority) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3: Hybrid Sampling (Target size between min and max)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = df['category'].value_counts()\n",
    "target_size = int(np.mean(class_counts))  # Use average as target\n",
    "print(f\"Original class sizes:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    count = class_counts.get(cat, 0)\n",
    "    print(f\"  Class {cat}: {count} samples\")\n",
    "print(f\"\\nTarget size per class: {target_size} (average of all classes)\")\n",
    "\n",
    "samples_per_class = {}\n",
    "for cat in [-1, 0, 1]:\n",
    "    original_count = class_counts.get(cat, 0)\n",
    "    sampled_count = min(target_size, original_count)\n",
    "    will_oversample = target_size > original_count\n",
    "    samples_per_class[cat] = {\n",
    "        'original': original_count,\n",
    "        'sampled': sampled_count if not will_oversample else target_size,\n",
    "        'oversampled': will_oversample\n",
    "    }\n",
    "\n",
    "print(\"\\nSampling details:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    info = samples_per_class[cat]\n",
    "    status = \"⬆️ OVERSAMPLING\" if info['oversampled'] else \"⬇️ UNDERSAMPLING\"\n",
    "    print(f\"  Class {cat}: {info['original']:,} → {info['sampled']:,} {status}\")\n",
    "\n",
    "df_hybrid = pd.concat([\n",
    "    df[df['category'] == -1].sample(\n",
    "        min(target_size, class_counts[-1]), \n",
    "        replace=(target_size > class_counts[-1]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 0].sample(\n",
    "        min(target_size, class_counts[0]), \n",
    "        replace=(target_size > class_counts[0]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 1].sample(\n",
    "        min(target_size, class_counts[1]), \n",
    "        replace=(target_size > class_counts[1]), \n",
    "        random_state=42\n",
    "    )\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n📦 Total hybrid dataset: {len(df_hybrid)} samples ({len(df_hybrid)/len(df)*100:.1f}% of original)\")\n",
    "print(\"Hybrid distribution:\")\n",
    "print(df_hybrid['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL hybrid data for training, test on remaining original data\n",
    "train_df_hybrid = df_hybrid.copy()\n",
    "\n",
    "# Test on data not used in hybrid sampling\n",
    "remaining_indices_hybrid = df.index.difference(df_hybrid.index)\n",
    "if len(remaining_indices_hybrid) > 0:\n",
    "    test_df_hybrid = df.loc[remaining_indices_hybrid].sample(\n",
    "        min(len(remaining_indices_hybrid), int(len(df)*0.3)), \n",
    "        random_state=42\n",
    "    )\n",
    "else:\n",
    "    # If hybrid used all data, split normally\n",
    "    train_df_hybrid, test_df_hybrid = train_test_split(\n",
    "        df_hybrid, test_size=0.3, random_state=42, stratify=df_hybrid['category']\n",
    "    )\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_hybrid):,} samples (hybrid balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_hybrid):,} samples\")\n",
    "print(f\"   Test set is {len(test_df_hybrid)/len(df)*100:.1f}% of original data\")\n",
    "\n",
    "# === Function to train and evaluate ===\n",
    "def train_and_evaluate(train_df, test_df, strategy_name):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training with: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    train_df[\"tokens\"] = train_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    test_df[\"tokens\"] = test_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:  # Minimum 2 occurrences\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    test_df[\"tags\"] = test_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Drop rare signatures\n",
    "    min_occ = 3  # Lower threshold for balanced data\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(word_tag_dict)}\")\n",
    "    print(f\"Valid signatures: {len(valid_sigs)}\")\n",
    "    \n",
    "    # Predict\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in test_df[\"tags\"]]\n",
    "    test_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(test_df[\"pred\"] == test_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\nACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_df[\"category\"], test_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(test_df[\"category\"], test_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# === Run all strategies ===\n",
    "results = {}\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"COMPARING ALL SAMPLING STRATEGIES\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results['Balanced Undersampling'] = train_and_evaluate(\n",
    "    train_df_balanced.copy(), test_df_balanced.copy(), \n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results['Stratified (Original)'] = train_and_evaluate(\n",
    "    train_df_stratified.copy(), test_df_stratified.copy(), \n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results['Hybrid Sampling'] = train_and_evaluate(\n",
    "    train_df_hybrid.copy(), test_df_hybrid.copy(), \n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === Final comparison ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nData Usage Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original dataset: {len(df):,} samples\")\n",
    "print(f\"  Strategy 1 (Balanced):  {len(df_balanced):,} samples ({len(df_balanced)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Strategy 2 (Stratified): {len(df):,} samples (100.0%)\")\n",
    "print(f\"  Strategy 3 (Hybrid):     {len(df_hybrid):,} samples ({len(df_hybrid)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nAccuracy Results:\")\n",
    "print(\"-\" * 60)\n",
    "for strategy, acc in results.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "best_strategy = max(results, key=results.get)\n",
    "print(f\"\\n🏆 BEST STRATEGY: {best_strategy}\")\n",
    "print(f\"   Accuracy: {results[best_strategy]:.4f} ({results[best_strategy]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d410a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:25:25.551766Z",
     "iopub.status.busy": "2025-10-26T12:25:25.551551Z",
     "iopub.status.idle": "2025-10-26T12:25:44.484361Z",
     "shell.execute_reply": "2025-10-26T12:25:44.483313Z"
    },
    "papermill": {
     "duration": 18.938965,
     "end_time": "2025-10-26T12:25:44.485538",
     "exception": false,
     "start_time": "2025-10-26T12:25:25.546573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORIGINAL DATASET\n",
      "============================================================\n",
      "Total samples: 37149\n",
      "\n",
      "Class distribution:\n",
      "category\n",
      " 1    15830\n",
      " 0    13042\n",
      "-1     8277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "category\n",
      " 1    0.426122\n",
      " 0    0.351073\n",
      "-1    0.222805\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "CREATING HOLDOUT TEST SET\n",
      "============================================================\n",
      "📦 Available for training: 29,719 samples (80%)\n",
      "🔒 HOLDOUT test set: 7,430 samples (20%)\n",
      "\n",
      "Holdout test distribution:\n",
      "category\n",
      " 1    3166\n",
      " 0    2609\n",
      "-1    1655\n",
      "Name: count, dtype: int64\n",
      "category\n",
      " 1    0.426110\n",
      " 0    0.351144\n",
      "-1    0.222746\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 1: Balanced Undersampling\n",
      "============================================================\n",
      "Original class counts:\n",
      "  Class -1: 6622 samples\n",
      "  Class 0: 10433 samples\n",
      "  Class 1: 12664 samples\n",
      "\n",
      "Minority class size: 6622\n",
      "\n",
      "✂️ Sampled 6622 from each class\n",
      "📦 Total balanced dataset: 19866 samples (66.8% of original)\n",
      "🗑️ Removed: 9853 samples (33.2%)\n",
      "\n",
      "Balanced distribution:\n",
      "category\n",
      " 0    6622\n",
      " 1    6622\n",
      "-1    6622\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 19,866 samples (balanced)\n",
      "🧪 Testing: 4,149 samples (from original distribution)\n",
      "   Test set is 14.0% of original data\n",
      "\n",
      "Test set distribution (original imbalance):\n",
      "category\n",
      " 1    0.410460\n",
      " 0    0.374789\n",
      "-1    0.214751\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 2: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "📦 Total dataset: 29719 samples (100% of original)\n",
      "   Training: 20803 samples (70%)\n",
      "   Testing: 8916 samples (30%)\n",
      "\n",
      "Training set distribution:\n",
      "category\n",
      " 1    8865\n",
      " 0    7303\n",
      "-1    4635\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "category\n",
      " 1    3799\n",
      " 0    3130\n",
      "-1    1987\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 3: Hybrid Sampling (Target size between min and max)\n",
      "============================================================\n",
      "Original class sizes:\n",
      "  Class -1: 6622 samples\n",
      "  Class 0: 10433 samples\n",
      "  Class 1: 12664 samples\n",
      "\n",
      "Target size per class: 9906 (average of all classes)\n",
      "\n",
      "Sampling details:\n",
      "  Class -1: 6,622 → 9,906 ⬆️ OVERSAMPLING\n",
      "  Class 0: 10,433 → 9,906 ⬇️ UNDERSAMPLING\n",
      "  Class 1: 12,664 → 9,906 ⬇️ UNDERSAMPLING\n",
      "\n",
      "📦 Total hybrid dataset: 26434 samples (88.9% of original)\n",
      "Hybrid distribution:\n",
      "category\n",
      " 0    9906\n",
      " 1    9906\n",
      "-1    6622\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 26,434 samples (hybrid balanced)\n",
      "🧪 Testing: 8,585 samples\n",
      "   Test set is 28.9% of original data\n",
      "\n",
      "############################################################\n",
      "COMPARING ALL SAMPLING STRATEGIES\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Training with: Balanced Undersampling\n",
      "============================================================\n",
      "Vocabulary size: 18735\n",
      "Valid signatures: 198\n",
      "\n",
      "ACCURACY: 0.7848 (78.48%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.69      0.77      0.73       891\n",
      "     Neutral       0.83      0.81      0.82      1555\n",
      "    Positive       0.81      0.77      0.79      1703\n",
      "\n",
      "    accuracy                           0.78      4149\n",
      "   macro avg       0.77      0.78      0.78      4149\n",
      "weighted avg       0.79      0.78      0.79      4149\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       688       103       100\n",
      "True Neu        84      1257       214\n",
      "True Pos       230       162      1311\n",
      "\n",
      "============================================================\n",
      "Training with: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "Vocabulary size: 19331\n",
      "Valid signatures: 111\n",
      "\n",
      "ACCURACY: 0.6391 (63.91%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.55      0.21      0.31      1987\n",
      "     Neutral       0.72      0.65      0.68      3130\n",
      "    Positive       0.61      0.86      0.71      3799\n",
      "\n",
      "    accuracy                           0.64      8916\n",
      "   macro avg       0.63      0.57      0.57      8916\n",
      "weighted avg       0.64      0.64      0.61      8916\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       423       481      1083\n",
      "True Neu        93      2025      1012\n",
      "True Pos       256       293      3250\n",
      "\n",
      "============================================================\n",
      "Training with: Hybrid Sampling\n",
      "============================================================\n",
      "Vocabulary size: 22030\n",
      "Valid signatures: 148\n",
      "\n",
      "ACCURACY: 0.7681 (76.81%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.46      0.59      1822\n",
      "     Neutral       0.78      0.84      0.81      3365\n",
      "    Positive       0.74      0.87      0.80      3398\n",
      "\n",
      "    accuracy                           0.77      8585\n",
      "   macro avg       0.78      0.72      0.73      8585\n",
      "weighted avg       0.77      0.77      0.76      8585\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       834       473       515\n",
      "True Neu        52      2819       494\n",
      "True Pos       129       328      2941\n",
      "\n",
      "############################################################\n",
      "TESTING ON HOLDOUT SET (20% UNSEEN DATA)\n",
      "############################################################\n",
      "\n",
      "🔒 Testing all 3 strategies on completely unseen 20% holdout data...\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Balanced Undersampling\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.6820 (68.20%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.54      0.65      0.59      1655\n",
      "     Neutral       0.77      0.68      0.72      2609\n",
      "    Positive       0.71      0.70      0.71      3166\n",
      "\n",
      "    accuracy                           0.68      7430\n",
      "   macro avg       0.67      0.68      0.67      7430\n",
      "weighted avg       0.69      0.68      0.68      7430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      1070       180       405\n",
      "True Neu       323      1768       518\n",
      "True Pos       582       355      2229\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.6322 (63.22%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.57      0.22      0.32      1655\n",
      "     Neutral       0.73      0.61      0.66      2609\n",
      "    Positive       0.60      0.86      0.71      3166\n",
      "\n",
      "    accuracy                           0.63      7430\n",
      "   macro avg       0.63      0.57      0.56      7430\n",
      "weighted avg       0.64      0.63      0.61      7430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       372       360       923\n",
      "True Neu        88      1592       929\n",
      "True Pos       195       238      2733\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Hybrid Sampling\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.6711 (67.11%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.60      0.34      0.43      1655\n",
      "     Neutral       0.72      0.70      0.71      2609\n",
      "    Positive       0.65      0.82      0.73      3166\n",
      "\n",
      "    accuracy                           0.67      7430\n",
      "   macro avg       0.66      0.62      0.62      7430\n",
      "weighted avg       0.67      0.67      0.66      7430\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg       560       375       720\n",
      "True Neu       131      1819       659\n",
      "True Pos       236       323      2607\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Data Usage Summary:\n",
      "------------------------------------------------------------\n",
      "Original dataset: 37,149 samples\n",
      "  Available for training: 29,719 samples (80%)\n",
      "  Holdout test set: 7,430 samples (20%)\n",
      "\n",
      "  Strategy 1 (Balanced):  19,866 samples (66.8% of available)\n",
      "  Strategy 2 (Stratified): 29,719 samples (100.0% of available)\n",
      "  Strategy 3 (Hybrid):     26,434 samples (88.9% of available)\n",
      "\n",
      "============================================================\n",
      "VALIDATION SET ACCURACY (from 80% data)\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.7848 (78.48%)\n",
      "Stratified (Original)              : 0.6391 (63.91%)\n",
      "Hybrid Sampling                    : 0.7681 (76.81%)\n",
      "\n",
      "============================================================\n",
      "🔒 HOLDOUT TEST SET ACCURACY (20% unseen data)\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.6820 (68.20%)\n",
      "Stratified (Original)              : 0.6322 (63.22%)\n",
      "Hybrid Sampling                    : 0.6711 (67.11%)\n",
      "\n",
      "============================================================\n",
      "COMPARISON: Validation vs Holdout\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.7848 → 0.6820 (-0.1028, -13.1%)\n",
      "Stratified (Original)              : 0.6391 → 0.6322 (-0.0069, -1.1%)\n",
      "Hybrid Sampling                    : 0.7681 → 0.6711 (-0.0970, -12.6%)\n",
      "\n",
      "🏆 BEST ON VALIDATION: Balanced Undersampling\n",
      "   Accuracy: 0.7848\n",
      "\n",
      "🏆 BEST ON HOLDOUT: Balanced Undersampling\n",
      "   Accuracy: 0.6820\n",
      "\n",
      "✅ Same strategy wins on both! Model generalizes well.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === 1️⃣ Load data ===\n",
    "df = pd.read_csv(\"/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Reddit_Data.csv\")\n",
    "df = df[['clean_comment', 'category']].dropna()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ORIGINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['category'].value_counts(normalize=True))\n",
    "\n",
    "# === HOLDOUT TEST SET: 20% of original data (NEVER used in training) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING HOLDOUT TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Split: 80% for training/sampling, 20% for final testing\n",
    "df_available, df_holdout_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(f\"📦 Available for training: {len(df_available):,} samples (80%)\")\n",
    "print(f\"🔒 HOLDOUT test set: {len(df_holdout_test):,} samples (20%)\")\n",
    "print(\"\\nHoldout test distribution:\")\n",
    "print(df_holdout_test['category'].value_counts())\n",
    "print(df_holdout_test['category'].value_counts(normalize=True))\n",
    "\n",
    "# Now use df_available instead of df for all sampling strategies\n",
    "df = df_available  # Replace df with the 80% available data\n",
    "\n",
    "# === STRATEGY 1: BALANCED UNDERSAMPLING ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1: Balanced Undersampling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the minority class size\n",
    "class_counts = df['category'].value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "print(f\"Original class counts:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    print(f\"  Class {cat}: {class_counts.get(cat, 0)} samples\")\n",
    "print(f\"\\nMinority class size: {min_class_size}\")\n",
    "\n",
    "# Sample equal amounts from each class\n",
    "df_balanced = pd.concat([\n",
    "    df[df['category'] == -1].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 0].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 1].sample(min_class_size, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "print(f\"\\n✂️ Sampled {min_class_size} from each class\")\n",
    "print(f\"📦 Total balanced dataset: {len(df_balanced)} samples ({len(df_balanced)/len(df)*100:.1f}% of original)\")\n",
    "print(f\"🗑️ Removed: {len(df) - len(df_balanced)} samples ({(len(df)-len(df_balanced))/len(df)*100:.1f}%)\")\n",
    "print(\"\\nBalanced distribution:\")\n",
    "print(df_balanced['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL balanced data for training, test on ORIGINAL distribution\n",
    "# This is more realistic - train balanced, test on real-world imbalanced data\n",
    "train_df_balanced = df_balanced.copy()\n",
    "\n",
    "# Create a separate test set from ORIGINAL data (not used in training)\n",
    "remaining_indices = df.index.difference(df_balanced.index)\n",
    "test_df_balanced = df.loc[remaining_indices].sample(\n",
    "    frac=0.3, random_state=42\n",
    ")  # 30% of remaining data\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_balanced):,} samples (balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_balanced):,} samples (from original distribution)\")\n",
    "print(f\"   Test set is {len(test_df_balanced)/len(df)*100:.1f}% of original data\")\n",
    "print(\"\\nTest set distribution (original imbalance):\")\n",
    "print(test_df_balanced['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 2: STRATIFIED SPLIT (keeps original distribution) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2: Stratified Split (Original Distribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_df_stratified, test_df_stratified = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(f\"📦 Total dataset: {len(df)} samples (100% of original)\")\n",
    "print(f\"   Training: {len(train_df_stratified)} samples (70%)\")\n",
    "print(f\"   Testing: {len(test_df_stratified)} samples (30%)\")\n",
    "print(\"\\nTraining set distribution:\")\n",
    "print(train_df_stratified['category'].value_counts())\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df_stratified['category'].value_counts())\n",
    "\n",
    "# === STRATEGY 3: WEIGHTED BALANCED (Oversample minority, undersample majority) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3: Hybrid Sampling (Target size between min and max)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = df['category'].value_counts()\n",
    "target_size = int(np.mean(class_counts))  # Use average as target\n",
    "print(f\"Original class sizes:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    count = class_counts.get(cat, 0)\n",
    "    print(f\"  Class {cat}: {count} samples\")\n",
    "print(f\"\\nTarget size per class: {target_size} (average of all classes)\")\n",
    "\n",
    "samples_per_class = {}\n",
    "for cat in [-1, 0, 1]:\n",
    "    original_count = class_counts.get(cat, 0)\n",
    "    sampled_count = min(target_size, original_count)\n",
    "    will_oversample = target_size > original_count\n",
    "    samples_per_class[cat] = {\n",
    "        'original': original_count,\n",
    "        'sampled': sampled_count if not will_oversample else target_size,\n",
    "        'oversampled': will_oversample\n",
    "    }\n",
    "\n",
    "print(\"\\nSampling details:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    info = samples_per_class[cat]\n",
    "    status = \"⬆️ OVERSAMPLING\" if info['oversampled'] else \"⬇️ UNDERSAMPLING\"\n",
    "    print(f\"  Class {cat}: {info['original']:,} → {info['sampled']:,} {status}\")\n",
    "\n",
    "df_hybrid = pd.concat([\n",
    "    df[df['category'] == -1].sample(\n",
    "        min(target_size, class_counts[-1]), \n",
    "        replace=(target_size > class_counts[-1]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 0].sample(\n",
    "        min(target_size, class_counts[0]), \n",
    "        replace=(target_size > class_counts[0]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 1].sample(\n",
    "        min(target_size, class_counts[1]), \n",
    "        replace=(target_size > class_counts[1]), \n",
    "        random_state=42\n",
    "    )\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n📦 Total hybrid dataset: {len(df_hybrid)} samples ({len(df_hybrid)/len(df)*100:.1f}% of original)\")\n",
    "print(\"Hybrid distribution:\")\n",
    "print(df_hybrid['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL hybrid data for training, test on remaining original data\n",
    "train_df_hybrid = df_hybrid.copy()\n",
    "\n",
    "# Test on data not used in hybrid sampling\n",
    "remaining_indices_hybrid = df.index.difference(df_hybrid.index)\n",
    "if len(remaining_indices_hybrid) > 0:\n",
    "    test_df_hybrid = df.loc[remaining_indices_hybrid].sample(\n",
    "        min(len(remaining_indices_hybrid), int(len(df)*0.3)), \n",
    "        random_state=42\n",
    "    )\n",
    "else:\n",
    "    # If hybrid used all data, split normally\n",
    "    train_df_hybrid, test_df_hybrid = train_test_split(\n",
    "        df_hybrid, test_size=0.3, random_state=42, stratify=df_hybrid['category']\n",
    "    )\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_hybrid):,} samples (hybrid balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_hybrid):,} samples\")\n",
    "print(f\"   Test set is {len(test_df_hybrid)/len(df)*100:.1f}% of original data\")\n",
    "\n",
    "# === Function to train and evaluate ===\n",
    "def train_and_evaluate(train_df, test_df, strategy_name):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training with: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    train_df[\"tokens\"] = train_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    test_df[\"tokens\"] = test_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:  # Minimum 2 occurrences\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    test_df[\"tags\"] = test_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Drop rare signatures\n",
    "    min_occ = 3  # Lower threshold for balanced data\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(word_tag_dict)}\")\n",
    "    print(f\"Valid signatures: {len(valid_sigs)}\")\n",
    "    \n",
    "    # Predict\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in test_df[\"tags\"]]\n",
    "    test_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(test_df[\"pred\"] == test_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\nACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_df[\"category\"], test_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(test_df[\"category\"], test_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# === Run all strategies ===\n",
    "results = {}\n",
    "results_holdout = {}\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"COMPARING ALL SAMPLING STRATEGIES\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results['Balanced Undersampling'] = train_and_evaluate(\n",
    "    train_df_balanced.copy(), test_df_balanced.copy(), \n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results['Stratified (Original)'] = train_and_evaluate(\n",
    "    train_df_stratified.copy(), test_df_stratified.copy(), \n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results['Hybrid Sampling'] = train_and_evaluate(\n",
    "    train_df_hybrid.copy(), test_df_hybrid.copy(), \n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === NOW TEST ON HOLDOUT SET ===\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"TESTING ON HOLDOUT SET (20% UNSEEN DATA)\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "print(\"\\n🔒 Testing all 3 strategies on completely unseen 20% holdout data...\")\n",
    "\n",
    "# We need to save the trained models from best strategy\n",
    "# Let's retrain and test on holdout for each strategy\n",
    "\n",
    "def test_on_holdout(train_df, holdout_df, strategy_name):\n",
    "    \"\"\"Train on strategy data, test on holdout\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"HOLDOUT TEST: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    # Process training data\n",
    "    train_df[\"tokens\"] = train_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    # Process HOLDOUT data\n",
    "    holdout_df[\"tokens\"] = holdout_df[\"clean_comment\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities from TRAINING only\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    holdout_df[\"tags\"] = holdout_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table from TRAINING only\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    min_occ = 3\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    # Predict on HOLDOUT\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in holdout_df[\"tags\"]]\n",
    "    holdout_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(holdout_df[\"pred\"] == holdout_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\n🔒 HOLDOUT ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(holdout_df[\"category\"], holdout_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(holdout_df[\"category\"], holdout_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Test each strategy on holdout\n",
    "results_holdout['Balanced Undersampling'] = test_on_holdout(\n",
    "    train_df_balanced.copy(), df_holdout_test.copy(),\n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results_holdout['Stratified (Original)'] = test_on_holdout(\n",
    "    train_df_stratified.copy(), df_holdout_test.copy(),\n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results_holdout['Hybrid Sampling'] = test_on_holdout(\n",
    "    train_df_hybrid.copy(), df_holdout_test.copy(),\n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === Final comparison ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nData Usage Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original dataset: {len(df) + len(df_holdout_test):,} samples\")\n",
    "print(f\"  Available for training: {len(df):,} samples (80%)\")\n",
    "print(f\"  Holdout test set: {len(df_holdout_test):,} samples (20%)\")\n",
    "print(f\"\\n  Strategy 1 (Balanced):  {len(df_balanced):,} samples ({len(df_balanced)/len(df)*100:.1f}% of available)\")\n",
    "print(f\"  Strategy 2 (Stratified): {len(df):,} samples (100.0% of available)\")\n",
    "print(f\"  Strategy 3 (Hybrid):     {len(df_hybrid):,} samples ({len(df_hybrid)/len(df)*100:.1f}% of available)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION SET ACCURACY (from 80% data)\")\n",
    "print(\"=\"*60)\n",
    "for strategy, acc in results.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔒 HOLDOUT TEST SET ACCURACY (20% unseen data)\")\n",
    "print(\"=\"*60)\n",
    "for strategy, acc in results_holdout.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Validation vs Holdout\")\n",
    "print(\"=\"*60)\n",
    "for strategy in results.keys():\n",
    "    val_acc = results[strategy]\n",
    "    holdout_acc = results_holdout[strategy]\n",
    "    diff = holdout_acc - val_acc\n",
    "    diff_pct = (diff / val_acc * 100) if val_acc > 0 else 0\n",
    "    print(f\"{strategy:35s}: {val_acc:.4f} → {holdout_acc:.4f} ({diff:+.4f}, {diff_pct:+.1f}%)\")\n",
    "\n",
    "best_strategy_val = max(results, key=results.get)\n",
    "best_strategy_holdout = max(results_holdout, key=results_holdout.get)\n",
    "\n",
    "print(f\"\\n🏆 BEST ON VALIDATION: {best_strategy_val}\")\n",
    "print(f\"   Accuracy: {results[best_strategy_val]:.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 BEST ON HOLDOUT: {best_strategy_holdout}\")\n",
    "print(f\"   Accuracy: {results_holdout[best_strategy_holdout]:.4f}\")\n",
    "\n",
    "if best_strategy_val == best_strategy_holdout:\n",
    "    print(f\"\\n✅ Same strategy wins on both! Model generalizes well.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Different winners - possible overfitting or variance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1d2104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:25:44.496070Z",
     "iopub.status.busy": "2025-10-26T12:25:44.495811Z",
     "iopub.status.idle": "2025-10-26T12:26:56.111335Z",
     "shell.execute_reply": "2025-10-26T12:26:56.110508Z"
    },
    "papermill": {
     "duration": 71.627069,
     "end_time": "2025-10-26T12:26:56.117403",
     "exception": false,
     "start_time": "2025-10-26T12:25:44.490334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ORIGINAL DATASET\n",
      "============================================================\n",
      "Total samples: 162969\n",
      "\n",
      "Class distribution:\n",
      "category\n",
      " 1.0    72249\n",
      " 0.0    55211\n",
      "-1.0    35509\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class proportions:\n",
      "category\n",
      " 1.0    0.443330\n",
      " 0.0    0.338782\n",
      "-1.0    0.217888\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "CREATING HOLDOUT TEST SET\n",
      "============================================================\n",
      "📦 Available for training: 130,375 samples (80%)\n",
      "🔒 HOLDOUT test set: 32,594 samples (20%)\n",
      "\n",
      "Holdout test distribution:\n",
      "category\n",
      " 1.0    14450\n",
      " 0.0    11042\n",
      "-1.0     7102\n",
      "Name: count, dtype: int64\n",
      "category\n",
      " 1.0    0.443333\n",
      " 0.0    0.338774\n",
      "-1.0    0.217893\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 1: Balanced Undersampling\n",
      "============================================================\n",
      "Original class counts:\n",
      "  Class -1: 28407 samples\n",
      "  Class 0: 44169 samples\n",
      "  Class 1: 57799 samples\n",
      "\n",
      "Minority class size: 28407\n",
      "\n",
      "✂️ Sampled 28407 from each class\n",
      "📦 Total balanced dataset: 85221 samples (65.4% of original)\n",
      "🗑️ Removed: 45154 samples (34.6%)\n",
      "\n",
      "Balanced distribution:\n",
      "category\n",
      " 0.0    28407\n",
      " 1.0    28407\n",
      "-1.0    28407\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 85,221 samples (balanced)\n",
      "🧪 Testing: 18,665 samples (from original distribution)\n",
      "   Test set is 14.3% of original data\n",
      "\n",
      "Test set distribution (original imbalance):\n",
      "category\n",
      " 1.0    0.441414\n",
      " 0.0    0.339673\n",
      "-1.0    0.218912\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 2: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "📦 Total dataset: 130375 samples (100% of original)\n",
      "   Training: 91262 samples (70%)\n",
      "   Testing: 39113 samples (30%)\n",
      "\n",
      "Training set distribution:\n",
      "category\n",
      " 1.0    40459\n",
      " 0.0    30918\n",
      "-1.0    19885\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set distribution:\n",
      "category\n",
      " 1.0    17340\n",
      " 0.0    13251\n",
      "-1.0     8522\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "STRATEGY 3: Hybrid Sampling (Target size between min and max)\n",
      "============================================================\n",
      "Original class sizes:\n",
      "  Class -1: 28407 samples\n",
      "  Class 0: 44169 samples\n",
      "  Class 1: 57799 samples\n",
      "\n",
      "Target size per class: 43458 (average of all classes)\n",
      "\n",
      "Sampling details:\n",
      "  Class -1: 28,407 → 43,458 ⬆️ OVERSAMPLING\n",
      "  Class 0: 44,169 → 43,458 ⬇️ UNDERSAMPLING\n",
      "  Class 1: 57,799 → 43,458 ⬇️ UNDERSAMPLING\n",
      "\n",
      "📦 Total hybrid dataset: 115323 samples (88.5% of original)\n",
      "Hybrid distribution:\n",
      "category\n",
      " 1.0    43458\n",
      " 0.0    43458\n",
      "-1.0    28407\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📚 Training: 115,323 samples (hybrid balanced)\n",
      "🧪 Testing: 38,097 samples\n",
      "   Test set is 29.2% of original data\n",
      "\n",
      "############################################################\n",
      "COMPARING ALL SAMPLING STRATEGIES\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Training with: Balanced Undersampling\n",
      "============================================================\n",
      "Vocabulary size: 27737\n",
      "Valid signatures: 340\n",
      "\n",
      "ACCURACY: 0.8346 (83.46%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.84      0.78      4086\n",
      "     Neutral       0.84      0.87      0.86      6340\n",
      "    Positive       0.90      0.80      0.85      8239\n",
      "\n",
      "    accuracy                           0.83     18665\n",
      "   macro avg       0.82      0.84      0.83     18665\n",
      "weighted avg       0.84      0.83      0.84     18665\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      3449       202       435\n",
      "True Neu       479      5527       334\n",
      "True Pos       793       845      6601\n",
      "\n",
      "============================================================\n",
      "Training with: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "Vocabulary size: 28535\n",
      "Valid signatures: 251\n",
      "\n",
      "ACCURACY: 0.7710 (77.10%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.58      0.65      8522\n",
      "     Neutral       0.80      0.75      0.78     13251\n",
      "    Positive       0.76      0.88      0.81     17340\n",
      "\n",
      "    accuracy                           0.77     39113\n",
      "   macro avg       0.77      0.74      0.75     39113\n",
      "weighted avg       0.77      0.77      0.77     39113\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      4920      1477      2125\n",
      "True Neu       516      9974      2761\n",
      "True Pos      1124       953     15263\n",
      "\n",
      "============================================================\n",
      "Training with: Hybrid Sampling\n",
      "============================================================\n",
      "Vocabulary size: 34279\n",
      "Valid signatures: 328\n",
      "\n",
      "ACCURACY: 0.8717 (87.17%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.76      0.78      8449\n",
      "     Neutral       0.86      0.95      0.91     12894\n",
      "    Positive       0.92      0.87      0.89     16754\n",
      "\n",
      "    accuracy                           0.87     38097\n",
      "   macro avg       0.86      0.86      0.86     38097\n",
      "weighted avg       0.87      0.87      0.87     38097\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      6423      1070       956\n",
      "True Neu       312     12262       320\n",
      "True Pos      1357       871     14526\n",
      "\n",
      "############################################################\n",
      "TESTING ON HOLDOUT SET (20% UNSEEN DATA)\n",
      "############################################################\n",
      "\n",
      "🔒 Testing all 3 strategies on completely unseen 20% holdout data...\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Balanced Undersampling\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.7918 (79.18%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.77      0.71      7102\n",
      "     Neutral       0.82      0.82      0.82     11042\n",
      "    Positive       0.85      0.78      0.81     14450\n",
      "\n",
      "    accuracy                           0.79     32594\n",
      "   macro avg       0.78      0.79      0.78     32594\n",
      "weighted avg       0.80      0.79      0.79     32594\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      5471       483      1148\n",
      "True Neu      1150      9038       854\n",
      "True Pos      1707      1445     11298\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Stratified Split (Original Distribution)\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.7701 (77.01%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.58      0.65      7102\n",
      "     Neutral       0.80      0.76      0.78     11042\n",
      "    Positive       0.76      0.88      0.81     14450\n",
      "\n",
      "    accuracy                           0.77     32594\n",
      "   macro avg       0.77      0.74      0.75     32594\n",
      "weighted avg       0.77      0.77      0.77     32594\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      4089      1245      1768\n",
      "True Neu       452      8349      2241\n",
      "True Pos       999       787     12664\n",
      "\n",
      "============================================================\n",
      "HOLDOUT TEST: Hybrid Sampling\n",
      "============================================================\n",
      "\n",
      "🔒 HOLDOUT ACCURACY: 0.8287 (82.87%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.70      0.71      7102\n",
      "     Neutral       0.84      0.88      0.86     11042\n",
      "    Positive       0.87      0.85      0.86     14450\n",
      "\n",
      "    accuracy                           0.83     32594\n",
      "   macro avg       0.81      0.81      0.81     32594\n",
      "weighted avg       0.83      0.83      0.83     32594\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred Neg  Pred Neu  Pred Pos\n",
      "True Neg      4960      1063      1079\n",
      "True Neu       563      9707       772\n",
      "True Pos      1316       791     12343\n",
      "\n",
      "============================================================\n",
      "FINAL COMPARISON\n",
      "============================================================\n",
      "\n",
      "Data Usage Summary:\n",
      "------------------------------------------------------------\n",
      "Original dataset: 162,969 samples\n",
      "  Available for training: 130,375 samples (80%)\n",
      "  Holdout test set: 32,594 samples (20%)\n",
      "\n",
      "  Strategy 1 (Balanced):  85,221 samples (65.4% of available)\n",
      "  Strategy 2 (Stratified): 130,375 samples (100.0% of available)\n",
      "  Strategy 3 (Hybrid):     115,323 samples (88.5% of available)\n",
      "\n",
      "============================================================\n",
      "VALIDATION SET ACCURACY (from 80% data)\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.8346 (83.46%)\n",
      "Stratified (Original)              : 0.7710 (77.10%)\n",
      "Hybrid Sampling                    : 0.8717 (87.17%)\n",
      "\n",
      "============================================================\n",
      "🔒 HOLDOUT TEST SET ACCURACY (20% unseen data)\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.7918 (79.18%)\n",
      "Stratified (Original)              : 0.7701 (77.01%)\n",
      "Hybrid Sampling                    : 0.8287 (82.87%)\n",
      "\n",
      "============================================================\n",
      "COMPARISON: Validation vs Holdout\n",
      "============================================================\n",
      "Balanced Undersampling             : 0.8346 → 0.7918 (-0.0428, -5.1%)\n",
      "Stratified (Original)              : 0.7710 → 0.7701 (-0.0009, -0.1%)\n",
      "Hybrid Sampling                    : 0.8717 → 0.8287 (-0.0431, -4.9%)\n",
      "\n",
      "🏆 BEST ON VALIDATION: Hybrid Sampling\n",
      "   Accuracy: 0.8717\n",
      "\n",
      "🏆 BEST ON HOLDOUT: Hybrid Sampling\n",
      "   Accuracy: 0.8287\n",
      "\n",
      "✅ Same strategy wins on both! Model generalizes well.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# === 1️⃣ Load data ===\n",
    "df = pd.read_csv(\"/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Twitter_Data.csv\")\n",
    "df = df[['clean_text', 'category']].dropna()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ORIGINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['category'].value_counts(normalize=True))\n",
    "\n",
    "# === HOLDOUT TEST SET: 20% of original data (NEVER used in training) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING HOLDOUT TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Split: 80% for training/sampling, 20% for final testing\n",
    "df_available, df_holdout_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(f\"📦 Available for training: {len(df_available):,} samples (80%)\")\n",
    "print(f\"🔒 HOLDOUT test set: {len(df_holdout_test):,} samples (20%)\")\n",
    "print(\"\\nHoldout test distribution:\")\n",
    "print(df_holdout_test['category'].value_counts())\n",
    "print(df_holdout_test['category'].value_counts(normalize=True))\n",
    "\n",
    "# Now use df_available instead of df for all sampling strategies\n",
    "df = df_available  # Replace df with the 80% available data\n",
    "\n",
    "# === STRATEGY 1: BALANCED UNDERSAMPLING ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1: Balanced Undersampling\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find the minority class size\n",
    "class_counts = df['category'].value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "print(f\"Original class counts:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    print(f\"  Class {cat}: {class_counts.get(cat, 0)} samples\")\n",
    "print(f\"\\nMinority class size: {min_class_size}\")\n",
    "\n",
    "# Sample equal amounts from each class\n",
    "df_balanced = pd.concat([\n",
    "    df[df['category'] == -1].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 0].sample(min_class_size, random_state=42),\n",
    "    df[df['category'] == 1].sample(min_class_size, random_state=42)\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "print(f\"\\n✂️ Sampled {min_class_size} from each class\")\n",
    "print(f\"📦 Total balanced dataset: {len(df_balanced)} samples ({len(df_balanced)/len(df)*100:.1f}% of original)\")\n",
    "print(f\"🗑️ Removed: {len(df) - len(df_balanced)} samples ({(len(df)-len(df_balanced))/len(df)*100:.1f}%)\")\n",
    "print(\"\\nBalanced distribution:\")\n",
    "print(df_balanced['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL balanced data for training, test on ORIGINAL distribution\n",
    "# This is more realistic - train balanced, test on real-world imbalanced data\n",
    "train_df_balanced = df_balanced.copy()\n",
    "\n",
    "# Create a separate test set from ORIGINAL data (not used in training)\n",
    "remaining_indices = df.index.difference(df_balanced.index)\n",
    "test_df_balanced = df.loc[remaining_indices].sample(\n",
    "    frac=0.3, random_state=42\n",
    ")  # 30% of remaining data\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_balanced):,} samples (balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_balanced):,} samples (from original distribution)\")\n",
    "print(f\"   Test set is {len(test_df_balanced)/len(df)*100:.1f}% of original data\")\n",
    "print(\"\\nTest set distribution (original imbalance):\")\n",
    "print(test_df_balanced['category'].value_counts(normalize=True))\n",
    "\n",
    "# === STRATEGY 2: STRATIFIED SPLIT (keeps original distribution) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2: Stratified Split (Original Distribution)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_df_stratified, test_df_stratified = train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "print(f\"📦 Total dataset: {len(df)} samples (100% of original)\")\n",
    "print(f\"   Training: {len(train_df_stratified)} samples (70%)\")\n",
    "print(f\"   Testing: {len(test_df_stratified)} samples (30%)\")\n",
    "print(\"\\nTraining set distribution:\")\n",
    "print(train_df_stratified['category'].value_counts())\n",
    "print(\"\\nTest set distribution:\")\n",
    "print(test_df_stratified['category'].value_counts())\n",
    "\n",
    "# === STRATEGY 3: WEIGHTED BALANCED (Oversample minority, undersample majority) ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3: Hybrid Sampling (Target size between min and max)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = df['category'].value_counts()\n",
    "target_size = int(np.mean(class_counts))  # Use average as target\n",
    "print(f\"Original class sizes:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    count = class_counts.get(cat, 0)\n",
    "    print(f\"  Class {cat}: {count} samples\")\n",
    "print(f\"\\nTarget size per class: {target_size} (average of all classes)\")\n",
    "\n",
    "samples_per_class = {}\n",
    "for cat in [-1, 0, 1]:\n",
    "    original_count = class_counts.get(cat, 0)\n",
    "    sampled_count = min(target_size, original_count)\n",
    "    will_oversample = target_size > original_count\n",
    "    samples_per_class[cat] = {\n",
    "        'original': original_count,\n",
    "        'sampled': sampled_count if not will_oversample else target_size,\n",
    "        'oversampled': will_oversample\n",
    "    }\n",
    "\n",
    "print(\"\\nSampling details:\")\n",
    "for cat in [-1, 0, 1]:\n",
    "    info = samples_per_class[cat]\n",
    "    status = \"⬆️ OVERSAMPLING\" if info['oversampled'] else \"⬇️ UNDERSAMPLING\"\n",
    "    print(f\"  Class {cat}: {info['original']:,} → {info['sampled']:,} {status}\")\n",
    "\n",
    "df_hybrid = pd.concat([\n",
    "    df[df['category'] == -1].sample(\n",
    "        min(target_size, class_counts[-1]), \n",
    "        replace=(target_size > class_counts[-1]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 0].sample(\n",
    "        min(target_size, class_counts[0]), \n",
    "        replace=(target_size > class_counts[0]), \n",
    "        random_state=42\n",
    "    ),\n",
    "    df[df['category'] == 1].sample(\n",
    "        min(target_size, class_counts[1]), \n",
    "        replace=(target_size > class_counts[1]), \n",
    "        random_state=42\n",
    "    )\n",
    "]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n📦 Total hybrid dataset: {len(df_hybrid)} samples ({len(df_hybrid)/len(df)*100:.1f}% of original)\")\n",
    "print(\"Hybrid distribution:\")\n",
    "print(df_hybrid['category'].value_counts())\n",
    "\n",
    "# Split: Use ALL hybrid data for training, test on remaining original data\n",
    "train_df_hybrid = df_hybrid.copy()\n",
    "\n",
    "# Test on data not used in hybrid sampling\n",
    "remaining_indices_hybrid = df.index.difference(df_hybrid.index)\n",
    "if len(remaining_indices_hybrid) > 0:\n",
    "    test_df_hybrid = df.loc[remaining_indices_hybrid].sample(\n",
    "        min(len(remaining_indices_hybrid), int(len(df)*0.3)), \n",
    "        random_state=42\n",
    "    )\n",
    "else:\n",
    "    # If hybrid used all data, split normally\n",
    "    train_df_hybrid, test_df_hybrid = train_test_split(\n",
    "        df_hybrid, test_size=0.3, random_state=42, stratify=df_hybrid['category']\n",
    "    )\n",
    "\n",
    "print(f\"\\n📚 Training: {len(train_df_hybrid):,} samples (hybrid balanced)\")\n",
    "print(f\"🧪 Testing: {len(test_df_hybrid):,} samples\")\n",
    "print(f\"   Test set is {len(test_df_hybrid)/len(df)*100:.1f}% of original data\")\n",
    "\n",
    "# === Function to train and evaluate ===\n",
    "def train_and_evaluate(train_df, test_df, strategy_name):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training with: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    train_df[\"tokens\"] = train_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    test_df[\"tokens\"] = test_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:  # Minimum 2 occurrences\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    test_df[\"tags\"] = test_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Drop rare signatures\n",
    "    min_occ = 3  # Lower threshold for balanced data\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(word_tag_dict)}\")\n",
    "    print(f\"Valid signatures: {len(valid_sigs)}\")\n",
    "    \n",
    "    # Predict\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in test_df[\"tags\"]]\n",
    "    test_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(test_df[\"pred\"] == test_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\nACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(test_df[\"category\"], test_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(test_df[\"category\"], test_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# === Run all strategies ===\n",
    "results = {}\n",
    "results_holdout = {}\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"COMPARING ALL SAMPLING STRATEGIES\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "results['Balanced Undersampling'] = train_and_evaluate(\n",
    "    train_df_balanced.copy(), test_df_balanced.copy(), \n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results['Stratified (Original)'] = train_and_evaluate(\n",
    "    train_df_stratified.copy(), test_df_stratified.copy(), \n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results['Hybrid Sampling'] = train_and_evaluate(\n",
    "    train_df_hybrid.copy(), test_df_hybrid.copy(), \n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === NOW TEST ON HOLDOUT SET ===\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"TESTING ON HOLDOUT SET (20% UNSEEN DATA)\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "print(\"\\n🔒 Testing all 3 strategies on completely unseen 20% holdout data...\")\n",
    "\n",
    "# We need to save the trained models from best strategy\n",
    "# Let's retrain and test on holdout for each strategy\n",
    "\n",
    "def test_on_holdout(train_df, holdout_df, strategy_name):\n",
    "    \"\"\"Train on strategy data, test on holdout\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"HOLDOUT TEST: {strategy_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Preprocessing\n",
    "    negation_words = {\"not\", \"no\", \"nor\", \"never\", \"n't\", \"don't\", \"dont\", \"cannot\"}\n",
    "    stop_words = set(stopwords.words(\"english\")) - negation_words\n",
    "    \n",
    "    def clean_tweet(text):\n",
    "        if not text:\n",
    "            return []\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "        text = text.lower().split()\n",
    "        return [w for w in text if w and w not in stop_words]\n",
    "    \n",
    "    # Process training data\n",
    "    train_df[\"tokens\"] = train_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    # Process HOLDOUT data\n",
    "    holdout_df[\"tokens\"] = holdout_df[\"clean_text\"].astype(str).apply(clean_tweet)\n",
    "    \n",
    "    # Build word probabilities from TRAINING only\n",
    "    vocab_stats = defaultdict(lambda: [0, 0, 0])\n",
    "    for _, row in train_df.iterrows():\n",
    "        cat = int(row[\"category\"])\n",
    "        for w in row[\"tokens\"]:\n",
    "            if cat == -1:\n",
    "                vocab_stats[w][0] += 1\n",
    "            elif cat == 0:\n",
    "                vocab_stats[w][1] += 1\n",
    "            elif cat == 1:\n",
    "                vocab_stats[w][2] += 1\n",
    "    \n",
    "    word_probs = {}\n",
    "    for w, counts in vocab_stats.items():\n",
    "        total = sum(counts)\n",
    "        if total >= 2:\n",
    "            probs = np.array(counts) / total\n",
    "            word_probs[w] = probs\n",
    "    \n",
    "    word_prob_df = pd.DataFrame(word_probs).T\n",
    "    word_prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    # Compute thresholds\n",
    "    max_p = word_prob_df.max(axis=1)\n",
    "    second_p = word_prob_df.apply(lambda x: sorted(x, reverse=True)[1], axis=1)\n",
    "    ratio = max_p / (second_p + 1e-9)\n",
    "    strong_thresh = np.percentile(ratio, 75)\n",
    "    mild_thresh = np.percentile(ratio, 55)\n",
    "    \n",
    "    # Tag words\n",
    "    def tag_word(row):\n",
    "        probs = row.values\n",
    "        labels = ['neg', 'neu', 'pos']\n",
    "        max_idx = np.argmax(probs)\n",
    "        sorted_probs = np.sort(probs)[::-1]\n",
    "        ratio = sorted_probs[0] / (sorted_probs[1] + 1e-9)\n",
    "        \n",
    "        if ratio >= strong_thresh:\n",
    "            return labels[max_idx]\n",
    "        elif ratio >= mild_thresh:\n",
    "            if labels[max_idx] == 'pos' and probs[1] > 0.15:\n",
    "                return 'mild_pos'\n",
    "            elif labels[max_idx] == 'neg' and probs[1] > 0.15:\n",
    "                return 'mild_neg'\n",
    "            else:\n",
    "                return labels[max_idx]\n",
    "        else:\n",
    "            return 'contextual'\n",
    "    \n",
    "    word_prob_df[\"tag\"] = word_prob_df.apply(tag_word, axis=1)\n",
    "    word_tag_dict = word_prob_df[\"tag\"].to_dict()\n",
    "    \n",
    "    # Tag tweets\n",
    "    def tag_tweet(tokens):\n",
    "        return [word_tag_dict[w] for w in tokens if w in word_tag_dict]\n",
    "    \n",
    "    train_df[\"tags\"] = train_df[\"tokens\"].apply(tag_tweet)\n",
    "    holdout_df[\"tags\"] = holdout_df[\"tokens\"].apply(tag_tweet)\n",
    "    \n",
    "    # Compress tags\n",
    "    def compress_tags(tags, max_tags=6):\n",
    "        tags = [t for t in tags if t != \"contextual\"]\n",
    "        if not tags:\n",
    "            return \"contextual_only\"\n",
    "        priority = {'pos': 3, 'neg': 3, 'mild_pos': 2, 'mild_neg': 2, 'neu': 1}\n",
    "        tags_sorted = sorted(tags, key=lambda t: priority.get(t, 0), reverse=True)[:max_tags]\n",
    "        tag_count = Counter(tags_sorted)\n",
    "        return \"_\".join([f\"{k}:{v}\" for k, v in sorted(tag_count.items())])\n",
    "    \n",
    "    train_df[\"signature\"] = train_df[\"tags\"].apply(compress_tags)\n",
    "    \n",
    "    # Build probability table from TRAINING only\n",
    "    alpha = 1\n",
    "    tag_class_counts = defaultdict(lambda: Counter())\n",
    "    \n",
    "    for _, row in train_df.iterrows():\n",
    "        tag_class_counts[row[\"signature\"]][int(row[\"category\"])] += 1\n",
    "    \n",
    "    prob_table = {}\n",
    "    for sig, class_counts in tag_class_counts.items():\n",
    "        total = sum(class_counts.values())\n",
    "        probs = {}\n",
    "        for c in [-1, 0, 1]:\n",
    "            probs[c] = (class_counts[c] + alpha) / (total + alpha * 3)\n",
    "        prob_table[sig] = probs\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_table).T.fillna(1/3)\n",
    "    prob_df.columns = ['p(-1)', 'p(0)', 'p(1)']\n",
    "    \n",
    "    min_occ = 3\n",
    "    valid_sigs = [sig for sig, counts in tag_class_counts.items() if sum(counts.values()) >= min_occ]\n",
    "    prob_df = prob_df.loc[valid_sigs]\n",
    "    \n",
    "    # Predict on HOLDOUT\n",
    "    def predict_argmax(tags):\n",
    "        sig = compress_tags(tags)\n",
    "        if sig not in prob_df.index:\n",
    "            return 0\n",
    "        row = prob_df.loc[sig]\n",
    "        max_col = row.idxmax()\n",
    "        class_val = int(max_col.split('(')[1].split(')')[0])\n",
    "        return class_val\n",
    "    \n",
    "    preds = [predict_argmax(tags) for tags in holdout_df[\"tags\"]]\n",
    "    holdout_df[\"pred\"] = preds\n",
    "    \n",
    "    accuracy = np.mean(holdout_df[\"pred\"] == holdout_df[\"category\"])\n",
    "    \n",
    "    # Metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(f\"\\n🔒 HOLDOUT ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(holdout_df[\"category\"], holdout_df[\"pred\"], \n",
    "                              target_names=['Negative', 'Neutral', 'Positive'],\n",
    "                              zero_division=0))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(holdout_df[\"category\"], holdout_df[\"pred\"])\n",
    "    cm_df = pd.DataFrame(cm, \n",
    "                         index=['True Neg', 'True Neu', 'True Pos'],\n",
    "                         columns=['Pred Neg', 'Pred Neu', 'Pred Pos'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Test each strategy on holdout\n",
    "results_holdout['Balanced Undersampling'] = test_on_holdout(\n",
    "    train_df_balanced.copy(), df_holdout_test.copy(),\n",
    "    \"Balanced Undersampling\"\n",
    ")\n",
    "\n",
    "results_holdout['Stratified (Original)'] = test_on_holdout(\n",
    "    train_df_stratified.copy(), df_holdout_test.copy(),\n",
    "    \"Stratified Split (Original Distribution)\"\n",
    ")\n",
    "\n",
    "results_holdout['Hybrid Sampling'] = test_on_holdout(\n",
    "    train_df_hybrid.copy(), df_holdout_test.copy(),\n",
    "    \"Hybrid Sampling\"\n",
    ")\n",
    "\n",
    "# === Final comparison ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nData Usage Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Original dataset: {len(df) + len(df_holdout_test):,} samples\")\n",
    "print(f\"  Available for training: {len(df):,} samples (80%)\")\n",
    "print(f\"  Holdout test set: {len(df_holdout_test):,} samples (20%)\")\n",
    "print(f\"\\n  Strategy 1 (Balanced):  {len(df_balanced):,} samples ({len(df_balanced)/len(df)*100:.1f}% of available)\")\n",
    "print(f\"  Strategy 2 (Stratified): {len(df):,} samples (100.0% of available)\")\n",
    "print(f\"  Strategy 3 (Hybrid):     {len(df_hybrid):,} samples ({len(df_hybrid)/len(df)*100:.1f}% of available)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION SET ACCURACY (from 80% data)\")\n",
    "print(\"=\"*60)\n",
    "for strategy, acc in results.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🔒 HOLDOUT TEST SET ACCURACY (20% unseen data)\")\n",
    "print(\"=\"*60)\n",
    "for strategy, acc in results_holdout.items():\n",
    "    print(f\"{strategy:35s}: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Validation vs Holdout\")\n",
    "print(\"=\"*60)\n",
    "for strategy in results.keys():\n",
    "    val_acc = results[strategy]\n",
    "    holdout_acc = results_holdout[strategy]\n",
    "    diff = holdout_acc - val_acc\n",
    "    diff_pct = (diff / val_acc * 100) if val_acc > 0 else 0\n",
    "    print(f\"{strategy:35s}: {val_acc:.4f} → {holdout_acc:.4f} ({diff:+.4f}, {diff_pct:+.1f}%)\")\n",
    "\n",
    "best_strategy_val = max(results, key=results.get)\n",
    "best_strategy_holdout = max(results_holdout, key=results_holdout.get)\n",
    "\n",
    "print(f\"\\n🏆 BEST ON VALIDATION: {best_strategy_val}\")\n",
    "print(f\"   Accuracy: {results[best_strategy_val]:.4f}\")\n",
    "\n",
    "print(f\"\\n🏆 BEST ON HOLDOUT: {best_strategy_holdout}\")\n",
    "print(f\"   Accuracy: {results_holdout[best_strategy_holdout]:.4f}\")\n",
    "\n",
    "if best_strategy_val == best_strategy_holdout:\n",
    "    print(f\"\\n✅ Same strategy wins on both! Model generalizes well.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Different winners - possible overfitting or variance.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 429085,
     "sourceId": 815876,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.594169,
   "end_time": "2025-10-26T12:26:56.640653",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-26T12:24:25.046484",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
